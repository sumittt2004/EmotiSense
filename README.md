# EmotiSense ğŸ˜ƒğŸ˜ğŸ˜ 
**AI-Powered Real-Time Emotion Detection System**


**EmotiSense** is a real-time emotion detection system that uses computer vision and facial landmark analysis to infer human emotions from live webcam input. The project is designed for **learning, demonstration, and portfolio use**, with a strong focus on explainable AI and clean system design.

---
## ğŸŒ Live Demo

**[ğŸš€ Try EmotiSense Live](https://emotisense-ai.streamlit.app)** - No installation required!

---

## ğŸš€ Features

* ğŸ¥ Real-time webcam-based face analysis
* ğŸ§  Emotion detection using **rule-based logic** on facial landmarks
* ğŸ‘ï¸ MediaPipe Face Mesh (468 landmarks)
* ğŸ›ï¸ Interactive controls for calibration and UI toggles
* ğŸ“Š Emotion confidence scoring
* ğŸ§© Modular, easy-to-understand codebase

---

## ğŸ§  Emotions Supported

* Happy ğŸ˜Š
* Sad ğŸ˜¢
* Angry ğŸ˜ 
* Surprised ğŸ˜²
* Neutral ğŸ˜

> Emotions are inferred using explainable geometric ratios (mouth openness, eyebrow movement, eye openness), not a black-box model.

---

## ğŸ—ï¸ Project Architecture

```text
EmotiSense/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py               # Main application (entry point)
â”‚   â”œâ”€â”€ face_mesh.py         # MediaPipe Face Mesh detector
â”‚   â”œâ”€â”€ emotion_rules.py     # Rule-based emotion logic
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ face_landmarker.task # MediaPipe model
â”‚
â”œâ”€â”€ venv/                    # Virtual environment
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

| Category        | Tools / Libraries             |
| --------------- | ----------------------------- |
| Language        | Python 3.10+                  |
| Computer Vision | OpenCV                        |
| Face Landmarks  | MediaPipe Face Mesh           |
| AI Logic        | Rule-based geometric analysis |
| Environment     | Virtualenv                    |

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/sumittt2004/EmotiSense 
cd EmotiSense
```

### 2ï¸âƒ£ Create virtual environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run the Application

```bash
python src/app.py
```

---

## ğŸ® Controls

| Key         | Action                 |
| ----------- | ---------------------- |
| `C`         | Calibrate neutral face |
| `L`         | Toggle face landmarks  |
| `E`         | Toggle emotion display |
| `Q` / `ESC` | Exit application       |

---

## ğŸ§ª How Emotion Detection Works

Instead of using a pre-trained deep learning classifier, EmotiSense:

1. Detects 468 facial landmarks using MediaPipe
2. Measures facial geometry (distances & ratios)
3. Compares them against calibrated neutral values
4. Applies rule-based thresholds
5. Outputs emotion + confidence score

This approach ensures:

* âœ” Explainability
* âœ” Lightweight execution
* âœ” No dataset bias


---

## ğŸ¯ Use Cases

* AI / CV portfolio project
* Emotion-aware applications
* Humanâ€“Computer Interaction research
* Learning MediaPipe & facial landmarks
* Interview demonstrations

---

## ğŸ”® Future Improvements

* Add deep learning emotion classifier (CNN)
* Multi-face emotion detection
* Emotion timeline analytics
* Streamlit web deployment
* Dataset-based benchmarking

---

## ğŸ“¬ Contact & Support

- **Author:** Sumit Mishra
- **GitHub:** [@sumittt.2004](https://github.com/sumittt2004)
- **Linkedin:** [Sumit Mishra](https://www.linkedin.com/in/mishra-sumit-/)

---

## â­ If you like this project

Give it a â­ on GitHub and feel free to fork or contribute!
